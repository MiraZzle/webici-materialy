# Prednaska 6

1. Sketch the physical query plan obtained by (1) the canonical translation to relational algebra, (2) selection pushing, (3) mapping each relational operator to a MapReduce job. It is enough to provide the result of step (3).

(1) the canonical translation to relational
algebra

```
\gamma_count(X)
    |
\select_{city in {'Springfield', 'Los Angeles', 'Annapolis'}} and age >= 30
    |
Student
```

HDFS - takes SQL, translates it into canonical algebra - each RA operation is actually implemented as a map task in DFS

2. How many Map tasks will be started by Hadoop to execute the first stage in the bottom-
   up evaluation of this plan? Give a simple estimate and briefly justify your answer.

As many as there are junks in the input:
`|Students| / chunk_size = 10_000 / 200 = 50`

FUN FACT:
Spotify has a batch processing module called Luigi: [GitHub for Luigi](https://github.com/spotify/luigi)

3. In your implementation, does it make sense to re-use the Reducer function code unchanged for a Combiner? Briefly justify your answer.

Yes, summation is both commutative and associative -> we can use combiner. Not the case for `yield ("result", len(values))`

4. Letâ€™s consider class CountAggr just implemented (not using a combiner). What is the communication cost of the implemented algorithm? Measure the cost in number of tuples.

Input of the map tasks `|select city and age|`

approx = `10_000 * 3/200 * 20/50 = X` assuming uniform distribution

Input of the reduce tasks:

`X` aswell, because we are passing the values from map as `(1 - same key for all outputs from map, 1 = value)`

Total communication cost:
`|map input| + |reduce input| = X + X = 2X`
